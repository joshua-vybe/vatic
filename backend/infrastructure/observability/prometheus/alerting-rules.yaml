apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: vatic-prop-alerts
  namespace: monitoring
spec:
  groups:
  - name: latency.rules
    interval: 30s
    rules:
    - alert: HighP99Latency
      expr: histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, job)) > 0.01
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High p99 latency detected"
        description: "p99 latency is {{ $value }}s, exceeding 10ms threshold"
  - name: error.rules
    interval: 30s
    rules:
    - alert: HighErrorRate
      expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.01
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "High error rate detected"
        description: "Error rate is {{ $value }}%, exceeding 1% threshold"
  - name: kafka.rules
    interval: 30s
    rules:
    - alert: HighKafkaConsumerLag
      expr: kafka_consumer_lag > 1000
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High Kafka consumer lag detected"
        description: "Kafka consumer lag is {{ $value }} messages for topic {{ $labels.topic }}"
  - name: service.rules
    interval: 30s
    rules:
    - alert: ServiceDown
      expr: up{job=~"core-service|market-data-service|monte-carlo-service|websocket-service|report-service"} == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "Service is down"
        description: "Service {{ $labels.job }} is down"
  - name: resource.rules
    interval: 30s
    rules:
    - alert: HighMemoryUsage
      expr: container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.85
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High memory usage detected"
        description: "Memory usage is {{ $value }}% for {{ $labels.pod }}"
